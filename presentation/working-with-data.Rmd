---
title: "Working with Data (Summer 2021)"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
    theme: lumen
    keep_md: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, readxl, googlesheets4, readstata13, magrittr, cansim, stats, broom, modelsummary, flextable, here)
```

The main objective of this R bootcamp is to introduce R programming to incoming MFRE students. The content of this session is adapted from [Open Case Studies](https://www.opencasestudies.org/ocs-bp-co2-emissions/#Data_Analysis). If you spot any errors or issues or any other feedback, please send me a message on Canvas or at krisha.lim[at]ubc.ca. 

# Before we get started

Let's load the packages we will use in this session.

```{r pacman, eval = FALSE}
pacman::p_load(tidyverse, readxl, googlesheets4, readstata13, magrittr, cansim, stats, broom, modelsummary, flextable, here)
```

# Data Import

You will likely have to import data into R for your MFRE courses, instead of typing the data by hand like we did in the previous session. We will load data into R from 5 different sources: 

 * Flat files (csv and txt)
 * Excel files (xlsx)
 * Stata data format (dta)
 * Google Sheet 
 * API (Statistics Canada)

## Flat files

It's common for people to save data in spreadsheets as comma-separated values (csv) or in text files (txt). To open a csv file in R, we use the `read_csv()` function of the `{tidyverse}` package, and the `here()` function of the `{here}` package. The `here()` function takes the folder and file names as inputs, which are enclosed by quotation marks and you wouldn't have to worry about to use back or forward slashes. 

The code below shows that we are reading the file "yearly_co2_emissions.csv" saved in our data folder and assigning it to the data object called `carbon`. Assigning data to objects is one of the big difference between R and Stata, as R allows you to work with multiple data sets at once. 

```{r loaddata1, message = FALSE, warning = FALSE}
carbon <- read_csv(here("data", "yearly_co2_emissions.csv"))
```

  * If you don't use the `here()` function, you have to specify the full file path relative to the location of the R project (my working directory). My R project folder is called "2021-r-bootcamp". Inside this folder, I have multiple folders including "code" (where my current script is saved) and "data" (where data files are saved). To import the carbon emissions file, I will have to type in `carbon <- read_csv("data/yearly_co2_emissions.csv")`
  
  * Note: The `read_csv` function assumes fields are delimited by comma. If you want a more flexible way of reading text files, look up the `{readr}` package for other [functions](https://readr.tidyverse.org/). 
  
  * In FRE 501, Dr. Vercammen uses the base R `read.csv()` function. To load the csv file using this function, the code is `carbon <- read.csv(here("data", "yearly_co2_emissions.csv"), sep = ",", header = TRUE)`. This code will do the same thing as the `read_csv` function. The additional arguments you may see are `sep = ","`, which means that data is delimited by comma, and `header = TRUE`, which means that the first row should be treated as column names. 

To load in text files, use the `read.table()` function. The `sep = "\t"` argument indicates that the data is tab-delimited. The `header = TRUE` argument indicates that the first row should be treated as column names.

```{r loaddata1_txt, message = FALSE, warning = FALSE}
provinces <- read.table(here("data", "province.txt"), sep = "\t", header = TRUE)
```

## Excel xlsx format

Another way that spreadsheets are stored is in the Excel xlsx format. Sometimes, there are multiple sheets in one Excel file. The `read_xlsx()` function of the `{readxl}` package allows us to read files in xlsx format. 

```{r loaddata3_nosheet, message = FALSE, warning = FALSE}
gdp <- read_xlsx(here("data", "gdp_pc.xlsx"))
```

Sometimes there are multiple sheets in one spreadsheet. We use the argument `sheet = insert_sheet_number` to indicate the sheet we are importing. 

```{r loaddata3, message = FALSE, warning = FALSE}
energy_hist <- read_xlsx(here("data", "energy_use_per_person.xlsx"), sheet = 1)
energy_recent <- read_xlsx(here("data", "energy_use_per_person.xlsx"), sheet = 2)
```

If you look at the two imported sheets (either by typing `View(energy_hist)` or clicking the `energy_hist` object in the Environment tab in the upper right panel of RStudio), they contain data for the same countries. The only difference is that in the first sheet (`energy_hist`), the data is from 1960-1999, and the data in the second sheet (`energy_recent`) is from 2000-2015. We want to join `energy_hist` and `energy_recent`. There are many types of [joins](https://dplyr.tidyverse.org/reference/join.html), but for now we will do a full join, meaning the new data frame called `energy` will include all rows and columns in both `energy_hist` and `energy_recent`. The variable `country` is the common variable in both data frames that I used to link them together. 

```{r loaddata3_join}
energy <- full_join(energy_hist, energy_recent, by = c("country"))
```

There are many ways to do the same thing in R. In FRE 501, Dr. Vercammen's uses the base R `merge` function. You can look at the full documentation for more details (`?merge`). The syntax is `merge(x, y)` where `x` and `y` are both the names of your dataframes. If you want to keep all observations in `x` and only merge `y` based on a common variable (`country`), I will use the `all.x = TRUE` argument. Since we want to do a full join (although the output would be the same anyway), we will use the `all.x = TRUE, all.y = TRUE` arguments to indicate that we want all rows in `x` and all rows in `y` in the output. 
  
```{r loaddata3_merge}
energy_basemerge <- merge(energy_hist, energy_recent, by = c("country"), all.x = TRUE, all.y = TRUE)
```

  * If you look at `energy` and `energy_basemerge` in your Environment tab, you will notice that both of them have the same dimensions. 
  
## Stata dta format

Because you will use Stata in some of your classes, you may read in a Stata data format into R as well. We will use the `read.dta13` of the `{readstata13}` package. This function allows you to read Stata file formats from version 17 and older. 

```{r loaddata4, message = FALSE, warning = FALSE}
politics <- read.dta13(here("data", "politics.dta"), nonint.factors = TRUE)
```

  * The argument `nonint.factors = TRUE` is to keep factor labels instead of the value itself. You can try loading the data with and without that argument to see the difference. 

## Google Sheets 

It is also common now to share data using Google Sheets. We will use the `read_sheet("insert_link_here")` function of the `{googlesheets4}` package. This function will prompt you to provide authorization to the tidyverse API and log in with your Gmail credentials. One way to get around this step would be to add in the function `gs4_deauth()` before you use the `read_sheet()` function. 

```{r loaddata5, message = FALSE, warning = FALSE}
gs4_deauth() # so no need to sign in
disasters <- read_sheet("https://docs.google.com/spreadsheets/d/17s15o7jdDpGSKgsIboZdnYU2UxHtU9DHKNRmYVVgwJo/edit#gid=0", skip = 2) 
```
* When you open the Google sheet link in your browser, you will notice that the first two rows are the notes or the title of the table. The data actually starts in row 3. Because of this reason, we add the argument `skip = 2` to tell R to start reading the data from the third row.

## API - Statistics Canada

When you look for data online, you usually have the option to download the tables as a csv or xlsx file. You may also want to check online if someone has already written a package that connects to the data's server directly and load it into R. The advantage of doing this approach is that you can work with 'updated' data whenever you run the code, and you also save yourself time from having to save the table as a spreadsheet every time the table is updated. 

For example, you want to download the Estimated areas, yield, production, average farm price, and total farm value of principal field crops table from [Statistics Canada](https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=3210035901). A quick Google Search of "import stats can table in R" will reveal that someone already wrote the `{cansim}` package to do just that. The function we will use is called `get_cansim('insert_table_number_here'_)`. 

```{r loaddata6_statscan, message = FALSE, warning = FALSE}
ag <- get_cansim('32-10-0359-01')
```

There are other many other ways to import data into R, but these are the ones you will most likely need to know for your MFRE courses. 

# Data Exploration

You can view your data with the command `View(dataframe_name)` or click the data object in the Environment tab in the upper right panel of RStudio. These two actions will open a new tab in the upper left panel of RStudio. If you want to see your data in the console, simply type in the name of the data object into your console. 

Here are a few functions to inspect your data. We will use the  `politics` data as an example. 

Size: 

  * `dim(politics)` returns a vector with the number of rows in the first element, and the number of columns in the second element
  * `nrow(politics)` returns the number of rows
  * `ncol(politics)` returns the number of columns 
  
Content:

  * `head(politics)` returns the first 5 observations 
  * `tail(politics)` returns the last 5 observations
  * `politics %>% slice_head(n = 6)` returns the first 6 observations 
  * `politics %>% slice_tail(n = 7)` returns the last 7 observations
  * `politics %>% slice_sample(n = 10)` returns 10 observations selected at random 
  
Column Names:

  * `names(politics)` returns the column names 
  
Summary:

  * `str(politics)` shows the structure of the object and information about the class, length, and content of each column
  * `summary(politics)` returns the summary statistics of each column
  * `glimpse(politics)` returns the dimension of the data, the names and class of each column, and previous as many values per column. 

## Subsetting Data Frames

As we learned from the previous session, we use `[]` or `[[]]` or `$` to extract certain columns and rows from our data, we use  
  
  * `politics[1, 2]` To extract the first element in the second column of the table as a vector
  * `politics[[1]]` To extract the first column as a vector 
  * `politics[3,]` To extract the third row of the table as a data frame
  * `politics[,3]` To extract the third column of the table as a data frame
  * `politics[, -1]` To extract all the columns except the first column as a data frame
    * `politics[c(5:10), ]` To extract rows to 5 and all of the columns as a data frame. If you do not include a comma, you will get an error. By not specifying a value after the comma, you indicate that you want all the columns. 
  * `politics[, c(3:4)]` To extract the third and fourth columns as a data frame. Notice that there is a comma in front to indicate that we want all the rows. 
  * `politics["country_name"]` To extract the `country_name` column as a data frame 
    * `politics$country_name` To extract the `country_name` column as a vector

As you can see, there are so many different ways to extract values. The most common way we extract values in MFRE classes would be last point, `politics$country`. Most of the time, however, we'll just want to see the results from `table(politics$country_name)`

# Data Wrangling

From this point on, we will only work with 3 data frames: `carbon`, `gdp` and `politics`. 

Now that we have loaded the data in R and know what it looks like, we want to tidy the data before we proceed with our analysis. Tidy data allows us to use analyze the data more efficiently. Tidy data deals with the shape and structure of the data. You can read more about tidy data [here](https://vita.had.co.nz/papers/tidy-data.pdf) and [here](https://www.openscapes.org/blog/2020/10/12/tidy-data/). In summary, tidy data means that
  
  * each variable forms a column
  * each observation forms a row
  * each cell is a single measurement

## Reshaping Data

In the `politics` data, each row contains the values of variables associated with each country and year. This data frame is said to be in the "long" data format. If you look at the `carbon` and `gdp` data frames, you will notice that they are in the wide format. Each row is a country, and the columns are the different years we have observations for. We would not consider the `carbon` and `gdp` as tidy data. 

Most R functions expect your data to be in the "long" data format because it is more machine readable and is closer to the formatting of databases. In the `tidyr` package, we can use the `pivot_longer()` and `pivot_wider` columns to reshape our data. These functions are the equivalent of the `reshape long` and `reshape wide` in Stata. 

```{r carbon_sample}
carbon %>% 
  slice_sample(n = 3)
```

  * *Note*: Something else you might notice is that the column names start with a number. If you create your own dataframe in the future, I strongly recommend that you DO NOT use numbers as the first character of your variable name. To refer to the last column of the `carbon` data, for example, whose variable/column name is 2014, you will have to wrap the column name with a backtick. 


```{r backticks}
head(carbon$`2014`)
```

## Pivoting longer

We will now convert `carbon` to a long format. We want to collapse all emissions across the years into one column called "emissions." We then identify the year the data point comes from by creating a "year" variable. 

The `pivot_longer()` function takes four main arguments:
  * the (wide) data
  * *cols* are the names of the columns we use (or drop) to fill the new values variable
  * the *names_to* column variable we wish to create the *cols* provided
  * the *values_to* column variable we wish to create and fill with values associated with the *cols* provided
  
Let's now reshape the `carbon` data longer to create new columns for `year` and `emissions`. 

To create a long format of the `carbon` data, we use the following
  * the (wide) data - `carbon` 
  * *cols* include all columns except the country variable, so we can just put `-country`. Usually you can put the column names of interest as in `cols = col1:col5` or `cols = c(col1, col2, col5)`, but because our variable names start as numbers, it is not allowing us to use this format. 
  * the *names_to* column variable will be a character string of the name the column names these columns (1762:2014) will collapse into - `"year"`
  * the *values_to* column variable will be a character string of the name of the column the values of the collapsed columns will be inserted into - `"emissions"`
  
```{r pivot_long_carbon}
carbon_long <- carbon %>%
  pivot_longer(cols = -country,
               names_to = "year",
               values_to = "emissions")
```

Now we can take a look at the long data format. 

```{r carbon_long_look}
head(carbon_long)

# To always get the same random sample, use set.seed(number)
# set.seed(2021)
carbon_long %>% 
  slice_sample(n = 10)

str(carbon_long)
```

Notice that the `year` variable is of the `character (chr)` type, so we want to recode that variable to numeric. To create or modify columns as a function of existing columns, we use the `mutate(new_var_name = function_of_existing_vars)` function. To change the data type to numeric, we use the `as.numeric()` function.  

```{r to_numeric}
carbon_long <- carbon_long %>%
  mutate(year = as.numeric(year))

# Alternatively, you an also use carbon_long$year <- as.numeric(carbon_long$year)
```

The `gdp` data is in the same format, so let's reshape that one too. Notice how I used `%>%` to chain the commands together. 

```{r pivot_long_gdp, message = F, warning = F}
gdp_long <- gdp %>%
  pivot_longer(cols = -country, 
               names_to = "year",
               values_to = "gdp") %>%
  mutate(year = as.numeric(year),
         gdp = as.numeric(gdp))
head(gdp_long)
```

## Pivoting wider

In the case that we want to reshape the `carbon_long` back to its original "wide" data format, we can use the `pivot_wider()` function. This function takes three main arguments. 

  1. the data
  2. the *names_from* column whose values will become new column names
  3. the *values_from* column whose values will fill the new column variables. 
  
```{r pivot_carbon_back}
carbon_wide <- carbon_long %>%
  pivot_wider(names_from = "year",
              values_from = "emissions")
```

If you inspect the `carbon_wide` data frame, you will notice that this data frame is equivalent to the `carbon` data frame. 

## Selecting and Filtering

In the `politics` data frame, let's say I only want to keep the `country`, `year`, `v2x_libdem`, `v2x_regime`, and `region` variables. We will use the `select(col1, col2, ...)` function. 

```{r select, eval = FALSE}
politics %>% select(country_name, year, v2x_libdem, v2x_regime, region)
```

Alternatively, we can also drop the columns we do not want by adding a `-` symbol before the column name/s. 

```{r select_drop, eval = FALSE}
politics %>% select(-v2psnatpar_ord)
```

The output from the two codes above is a data frame of all the rows of the columns we selected, but the original data `politics` remains unchanged. To "save" this new data frame, we have to use the assignment operator `<-`. In the code below, we will just overwrite the original `politics` data.

```{r select_overwrite}
politics <- politics %>% select(country_name, year, v2x_libdem, v2x_regime, region)
```

Running the command `dim(politics)`, you will notice that we only have 5 columns left in our data frame. 

If we want to keep observations to those from years 1991-2014 only, we use the `filter()` function. 

```{r filter}
politics <- politics %>% filter(year >= 1991 & year <= 2014)

# To filter observations where region = Africa
# politics %>% filter(region == "Africa") 
```

We can use the pipe operator to chain the `select()` and `filter()` functions. Running this code will not change anything anymore because we already used the assignment operator. But it may be something you may want to do in the future and save yourself a few lines of code. 

```{r pipe, eval = FALSE}
politics <- politics %>% 
  select(country_name, year, v2x_libdem, v2x_regime, region) %>%
  filter(year >= 1991 & year <= 2014)
```

## Renaming columns

Let's say we want to rename the `country_name` column to `country`, `v2x_libdem` to `democracy`, and `v2x_regime` to regime. The function is `rename(new_name = old_name)`.

```{r rename}
politics <- politics %>% 
  rename(country = country_name,
         democracy = v2x_libdem,
         regime = v2x_regime)
```

  * In Dr. Vercammen's code, you will see that he renames variables using the `names()` and `which()` functions -- `names(politics)[which(names(politics) == "country")] = "country"`. 
  
## Joining our data together

Now we will join the three data frames together. I want to keep all observations in the `carbon_long` data, and only add in the `politics` and `gdp_long` data. So, this time, I will do a `left_join()`.

```{r join_all}
data <- carbon_long %>%
  left_join(gdp_long, by = c("country", "year")) %>%
  left_join(politics, by = c("country", "year")) %>% 
  filter(!is.na(emissions) & !is.na(region) & !is.na(gdp)) %>%
  filter(year >= 1991 & year <= 2014)

head(data)
```

You can also join data frames together using the base R `merge()` function, but you have to run this function twice because it only merges two data frames at once. You indicate `all.x = TRUE` for a left join, `all.y = TRUE` for a right join, and `all.x = TRUE, all.y = TRUE` for a full join.  

```{r merge, eval = FALSE}
carbon_gdp <- merge(carbon_long, gdp_long, by = c("country", "year"), all.x = TRUE)
merged <- merge(carbon_gdp, politics, by = c("country", "year"), all.x = TRUE)

merged <- merged %>%
  filter(!is.na(emissions) & !is.na(region) & !is.na(gdp)) %>%
  filter(year >= 1991 & year <= 2014)
```

## Creating new variables

We can create a new variable from existing variables using the `mutate()` function. For example, we want to create a new column that is the squared of GDP called `gdp_sq`.

```{r gdp_sq}
data <- data %>% 
  mutate(gdp_sq = gdp * gdp)
```

The `{base}` function to create a new column would be to run the following command: `data$gdp_sq <- data$gdp * data$gdp`

# Descriptive Statistics

To take a look at some summary statistics, we can use the built-in R functions.

  * `mean(data$emissions, na.rm = T)` - mean of `emissions`
  * `table(data$country)` to know the number of observations per country
  * `summary(data)` - summary statistics of the columns
  * `summary(data$emissions)` - summary statistics of the `emissions` variable
  
We can also look at some summary statistics by region. We use the `group_by()` function to group the observations. To calculate multiple summary statistics, we can use the `summarize()` function.

```{r summarize_new_col}
data %>% group_by(region) %>%
  summarize(n = n(), 
            avg_emissions = mean(emissions, na.rm = T), 
            median_gdp = median(gdp, na.rm = T)) %>%
  arrange(desc(median_gdp), desc(avg_emissions)) # arrange to order, desc() for descending
```

We use the `summarize_all()` to apply a particular function to all variables. For example, if we put `mean, na.rm = T` inside the parentheses, we will get the mean of all variables, and it will return `NA` for categorical variables. 

```{r summarize_all, warning = FALSE, message = FALSE}
data %>% 
  group_by(region) %>%
  summarize_all(mean, na.rm = T)
```

If we only want to summarize certain variables only, we can use the `summarize_at()` function. 

```{r summarize_at}
data %>%
  group_by(region) %>%
  summarize_at(vars(democracy, emissions), mean, na.rm = T)
```

If we only want to summarize numeric variables only, we can use the `summarize_if()` function.

```{r summarize_if}
data %>% 
  group_by(region) %>%
  summarize_if(is.numeric, mean, na.rm = T)
```

The `modelsummary` package allows you to produce very nice summary statistic plots for tidy data. You can read more [here](https://vincentarelbundock.github.io/modelsummary/articles/datasummary.html). 

```{r exploredata_cont, warning = FALSE, message = FALSE}
datasummary_skim(politics)
```

We need to add an argument `type = categorical` to see summary statistics for non-numeric data.

```{r exploredata_cat, warning = FALSE, message = FALSE}
datasummary_skim(data, type = "categorical")
```

We can export these tables to tex, pdf, docx, or html too. You can read on how to customize the tables [here](https://vincentarelbundock.github.io/modelsummary/articles/appearance.html).

```{r exploredata_export, warning = FALSE, message = FALSE}
datasummary_skim(data,
                 output = here("output", "categorical_summary_statistics.html"))
```

# Data Visualization (ggplot2)

There are functions in `{base}` R that will allows you to plot data. But in this session, we will look at the `ggplot2` package. Read this [tutorial/book](https://ggplot2-book.org/introduction.html) for an in-depth walk through. 

According to Hadley Wickham, "`ggplot2` is based on the Grammar of Graphics that allows you to compose graphs by combining independent components...The grammar tells us that a graphic maps the data to the aesthetic attributes (color, shape, size) of geometric objects (points, lines, bars)."

In Wickham's tutorial, he indicated that there are 3 main components for every ggplot2 plot.

  1. *data*
  2. A set of *aesthetic* mappings
  3. At least one layer which describes how to render each observations. Layers are usually created with a *geom* function. Common layers we will use are the following:
  
    a. `geom_line()` for trend lines, time series, etc. 
    b. `geom_point()` for scatter plots 
    c. `geom_boxplot()` for boxplots 
    d. `geom_bar()` and `geom_col()` for bar charts 
    e. `geom_histogram()` for histograms 
  
## Scatterplots   

Here is a simple example. The code below produces a scatterplot defined by:

  1. Data: `data` (I should have named the object differently!)
  2. Aesthetic mapping: gdp mapped to the x position, emissions to the y position
  3. Layer: points 

```{r first_plot}
options(scipen=99999)  # turn off scientific notation like 1e+06

ggplot(data, aes(x = gdp, y = emissions)) + 
  geom_point()
```

If we want to do a log transformation, we can just add `log()` before the variable name. 

```{r first_plot_log, warning = FALSE}
ggplot(data, aes(x = log(gdp), y = log(emissions))) + 
  geom_point()
```
  
Note the syntax. The data and aesthetic mapping are inside the `ggplot()` function, and the layer is adding with a `+`.  Since most maps plots a variable to x and y, the developers have indicated that the the first two arguments of `aes()` will be mapped to x and y. The code below will generate the same plot as above. 

```{r firstplot_noxy, warning = FALSE}
ggplot(data, aes(log(gdp), log(emissions))) + 
  geom_point()
```

We can add plot another variable to the plot by using other aesthetics such as color, shape, and size. The code below changes the color of the points based on country's region. 

```{r firstplot_region, warning = FALSE}
ggplot(data, aes(log(gdp), log(emissions), color = region)) + 
  geom_point()
```

We can also use the pipe operator. This method can be useful if you want to make changes to the data (i.e. filter or mutate) before plotting. For example, let's calculate the average emissions and average GDP per country, and plot its relationship. This will be our *base* graph, so I am assigning it to the object `p`. We will call it again later and add more layers to it. Now, whenever you type `p` in your console, you will see the plot in the plots tab on the lower left panel of RStudio.  

```{r avgplot}
p <- data %>% 
  group_by(country) %>%
  mutate(avg_emissions = mean(emissions, na.rm = T),
         avg_gdp = mean(gdp, na.rm = T)) %>%
  ggplot(aes(log(avg_gdp), log(avg_emissions))) +
  geom_point()

p
```

We build our plots iteratively. Now, let's add a title and label the axes of `p`. Since we always want to label our graph well, let's add these layers to `p`. 

```{r firstplot_labels}
p <- p + labs(title = "Relationship between Emissions and GDP",
              y = "Log GDP per capita", x = "Log CO2 per capita")
p
```

We can add a fitted line using `geom_smooth()` function. 

```{r firstplot_fittedline}
p + geom_smooth()
```

If we want to add a fitted line based on a linear model, we have to specify `geom_smooth(method = "lm")`. 

```{r firstplot_fittedline_lm}
p + geom_smooth(method = "lm")
```

If we want to change the background, there are multiple themes available in the [package](https://ggplot2.tidyverse.org/reference/ggtheme.html), and of course you can customize your own too. Let's say we want to use `theme_classic()` theme, we just add it as another layer and overwrite our `p` object again. 

```{r firstplot_theme}
p <- p + theme_classic()

p
```

To save the plot, we can use the `ggsave()` function. I am saving this file in another folder called output. You can save the plots to different formats too. You can also click the 'Export' button available in the 'Plots' tab, but this action is not good for reproducibility. Please do not take screenshots of the image and use that in your reports!

```{r firstplot_ggsave, message = FALSE}
ggsave(p, filename = here("output","emissions_gdp.png"))

ggsave(p, filename = here("output","emissions_gdp.jpg"))

ggsave(p, filename = here("output","emissions_gdp.pdf"))
```

## Boxplot 

We can also visualize the distribution of GDP within each region in 2010. We follow the structure, but now use `geom_boxplot()`. 

```{r boxplot_2010}
bp <- data %>% 
  filter(year == 2010) %>%
  ggplot(aes(region, gdp)) + 
  geom_boxplot() + 
  labs(title = "Distribution of GDP by Region, 2010",
              y = "GDP per capita", x = "Region") +
  theme_classic()

bp
```

We may want to edit the labels of the tick marks.

```{r boxplot_2010ticks}
bp + scale_x_discrete(labels = c("Africa", "Americas", "Mediterranean", "Europe", "SE Asia", "W Pacific"))
```

We can also flip the coordinates of the boxplot. Note that because we did not assign the tick mark labels to `bp`, as in did not use `bp + scale_x_discrete(labels = c("Africa", "Americas", "Mediterranean", "Europe", "SE Asia", "W Pacific"))`),`bp` remains unchanged. Hence the plot below shows the original labels. 

```{r boxplot_2010flipped}
bp + coord_flip()
```

## Line graphs

We may be interested in Canada's carbon emissions over time. To draw a line graph, we now use the `ggplot_line()` function. 

```{r geomline}
lp <- data %>% 
  filter(country == "Canada") %>% 
  ggplot(aes(x = year, y = emissions)) +
  geom_line(linetype = "dashed", color = "red") +
  theme_classic() +
  labs(title = "Canada's CO2 emissions, 1991-2014",
       y = "Total Emissions", 
       x = "Year")

lp
```

We can also add comma to the y-axis labels for easier reading. 

```{r}
lp + scale_y_continuous(labels = scales::comma) 
```

## Histograms

```{r hist, message = F, warning = F}
ggplot(data, aes(x = gdp)) + 
  geom_histogram() + 
  theme_classic() + 
  labs(title = "Income Distribution, 1991-2014",
       y = "Count",
       x = "GDP per capita") 
```

# Analysis

## Pairwise t-test
Let's say we want to compare the carbon emissions of Canada and Australia. We can visualize the distribution using a box plot. 

```{r can_usa}
data %>%
  filter(country == "Canada" | country == "Australia") %>% 
  group_by(country) %>%
  ggplot(aes(x = country, y = emissions)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::comma) + 
  labs(title = "Comparing Canada and Australia's emissions, 1991-2014",
       y = "Emissions",
       x = "Country")
```

The graph suggests some difference in the carbon emissions of the two countries. To formally test that the carbon emissions differ for these two countries, we can conduct a t-test using the `t.test()` function. We specify the formula `emissions ~ country` to test whether the emissions distribution is significantly different across the two countries. The test suggests that the mean emissions of the two countries are statistically different. 

```{r can_usa_ttest}
# filter data 
can_aus <- data %>%
  filter(country == "Canada" | country == "Australia")

options(scipen = 0) # to allow for scientific notation again 
can_aus_ttest <- t.test(emissions ~ country, data = can_aus)
can_aus_ttest
```

## Correlation

Our graph earlier suggests that there may be a relationship between emissions and GDP per capita. We can take a look at the correlation between these two variables. 

We will create 2 new variables - the country's average emissions and average GDP. 

```{r data_modified}
data <- data %>% 
  group_by(country) %>%
  mutate(avg_emissions = mean(emissions, na.rm = T),
         avg_gdp = mean(gdp, na.rm = T))
```

Then let us calculate the correlation coefficient using the Pearson method.

```{r pearson}
cor <- cor.test(data$avg_emissions, data$avg_gdp, method = "pearson")
cor

# cor$estimate will print the correlation coefficient 
str(cor) # to know how to extract list elements
```

The coefficient of `r round(cor$estimate, 2)` suggests that there is a weak correlation between these two variables. 

## Ordinary Least Squares 

Let's say we want to estimate the following equation: 

$$ 
emissions_i = b_0 + b_1 GDP_i + \varepsilon_i 
$$

To run an OLS regression, we use the `lm()` function of the `stats` package. The syntax is `lm(y ~ x1 + x2 + x3 + ...)`. Printing the object will only give you the coefficients. 

```{r reg1}
reg1 <- lm(emissions ~ gdp, data = data)
reg1
```

To get all the details of the regression, we use the `summary()` function. The output is similar to Stata's regression output. 

```{r reg1summary}
summary(reg1)
```

As mentioned earlier, regressions results is a list object. We can use the `$` and `[[]]` to extract information. To know the location or the element name, you can check in `str(summary(reg1))`. For example, we can just extract the coefficients of the regression. 

```{r reg1_coef}
summary(reg1)$coefficients
```

  